import random
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os
import json


def get_dataset_name(max_player, upper_value, dataset_num, start_from_zero):
    postfix = 'zero' if start_from_zero else 'nonzero'
    return f'N={max_player}_V={upper_value}_{postfix}_{dataset_num}games.json'


def mechanism_encoding(mechanism):
    enc = {'first': 0, 'second': 1, 'first+entry': 2, 'second+entry': 3}
    return enc[mechanism]


class HybridDataset(Dataset):
    """
    Hybrid mechanism & distribution dataset.

    The valuation distributions are generated by 'dataset/generate_game.py',
    including 'uniform' values and 'gaussian' values of different players,
    specified by args.distributions.

    While the mechanisms (first, second, first+entry and second+entry) are randomly picked
    each time the data is loaded, since it's independent of valuation distribution.
    """

    def __init__(self, args, data_dir, enlarge_times=1, is_test=False):
        self.mechanisms = args.mechanisms
        self.distributions = args.distributions
        self.max_player = args.max_player
        self.valuation_range = args.valuation_range
        self.upper_value = self.valuation_range - 1
        self.max_entry = args.max_entry
        self.test_size = args.test_size

        self.enlarge_times = enlarge_times
        self.is_test = is_test

        dataset_name = get_dataset_name(self.max_player, self.upper_value, args.dataset_size, args.start_from_zero)
        self.dataset = json.load(open(os.path.join(data_dir, dataset_name), 'r'))
        if args.combine_zero and not args.start_from_zero:
                zero_name = get_dataset_name(self.max_player, self.upper_value, args.dataset_size, True)
                zero_dataset = json.load(open(os.path.join(data_dir, zero_name),'r'))
                for key in self.dataset:
                        self.dataset[key] += zero_dataset[key]
        if self.is_test:
            self.dataset_size = self.test_size
        else:
            self.dataset_size = len(self.dataset['number']) - self.test_size

        prefix = 'test' if is_test else 'train'
        print(f'Successfully load {prefix} dataset:{dataset_name}, with size of {len(self)}')

    def __len__(self):
        return int(self.dataset_size * self.enlarge_times)

    def __getitem__(self, idx):

        idx = int(idx / self.enlarge_times)
        if self.is_test:
            cur_idx = idx
        else:
            cur_idx = idx + self.test_size

        # game type
        cur_mechanism = random.choice(self.mechanisms)
        if 'entry' in cur_mechanism:
            cur_entry = random.randint(0, self.max_entry + 1)
        else:
            cur_entry = 0

        # load valuation distribution
        cur_dist_type = random.choice(self.distributions)
        cur_player_num = self.dataset['number'][cur_idx]
        # uniform_value_hist or gaussian_value_hist (already padded to V)
        cur_player_dist = self.dataset[f'{cur_dist_type}_value_hist'][cur_idx]  # N_cur *V
        player_value_dists = np.array(
            cur_player_dist + [np.zeros(self.valuation_range)] * (self.max_player - cur_player_num))

        return cur_player_num, mechanism_encoding(cur_mechanism), cur_entry, player_value_dists


def get_train_loader(args, data_dir):
    train_loader = DataLoader(HybridDataset(args, data_dir, enlarge_times=args.train_enlarge, is_test=False),
                              batch_size=args.batch_size,
                              shuffle=True, )
    return train_loader


def get_test_loader(args, data_dir):
    test_loader = DataLoader(HybridDataset(args, data_dir, enlarge_times=args.test_enlarge, is_test=True),
                             batch_size=args.batch_size,
                             shuffle=False)

    return test_loader
